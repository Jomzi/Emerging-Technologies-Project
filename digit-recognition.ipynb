{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Digit Recognition Notebook</h1>\n",
    "<br>\n",
    "\n",
    "### Overview:\n",
    "\n",
    "This gives an overview of the mnist dataset, machine learning model and the discussion on its performance. The selected supervised algorithm for image classification is Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks Summary:\n",
    "##### Fully connected Neural Networks also known as Multi layer perceptron- \n",
    "\n",
    " - Please write a gentle introduction on Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitrec as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defalut Model Parameters:\n",
    "\n",
    "The below model parameters can be changed and tuned for performance. Please note that all model parameters must be given in the form of adictionary object. Further details on what each model parameters does can be obtined from sklean package: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html.\n",
    "<br>\n",
    "#### Neural Network Architecture:\n",
    "<li>Input nodes: 784 = No of pixels in a mnist data i.e. (28*28).</li>\n",
    "<li>Hidden node: This parameter is given as below (10, 10) means - 2 hidden layers with 10 nodes each.</li>\n",
    "<li>Output node: This is equal to the number of classes i.e - we have total of 0 to 9 classes. No of output nodes = 10.</li> \n",
    "<li>Activation function used is Relu.</li> \n",
    "<li>Learning rate 0.0001.</li> \n",
    "<li>Solver = Adam optimization.</li> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "- Unzipped MNIST data is stored in folder called mnist_data in home directory.\n",
    "- Loaded the testing and training data using MNIST library.\n",
    "- Laoding training features and corresponding labels.\n",
    "- Loading Testing features and corresponding labels.\n",
    "- Randomly shuffling the data and Normalising the training features (min_max normalization (-1, 1) normalisation from sckit learn package).\n",
    "- Conterting training and testing data to matrix or numpy form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relu Activation function:\n",
    "\n",
    "Rectifier linear unit or its more widely known name as ReLU becomes popular for the past several years since its performance  and speed. In contrast to other common activation functions like sigmoid, ReLU is a linear function. In other words, its derivative is either 0 or 1.\n",
    "i.e.f(x) = max(x, 0). Relu is suitable when we have large number of hidden layers because it is not sensitive to the problem of vanishing gradient (One of the main problem in sigmoid activation function). \n",
    "\n",
    "Ref: https://sefiks.com/2017/08/21/relu-as-neural-networks-activation-function/\n",
    "\n",
    "Ref: https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer/Solver Used:\n",
    "\n",
    "There are several otimzation that can be used with neural networks, some of them are - \n",
    "\n",
    "- Batch Gradient Descent\n",
    "- Mini Batch Gradient Descent\n",
    "- Stochastic gradient Descent\n",
    "- RMS Prop\n",
    "- Adam Optimization and more\n",
    "\n",
    "Here, we have utilzed adam optimization from sk-learn package as solver=Adam. Selected beta1=0.9, beta2=0.999, eplison=1e-08.\n",
    "\n",
    "#### Adam Optimization\n",
    "Adam is an update to the RMSProp optimizer. In this optimization algorithm, running averages of both the gradients and    the second moments of the gradients are used.\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "1. Initialize Weights and Biases.\n",
    "    2. For each iteration in epoch:\n",
    "        - Create Multiple batches here 7 batches are created.\n",
    "        - For each iteration in batch t:\n",
    "            Initialize Vdw=0, Sdw=0, Vdb=0, Sdb=0, epsilon = 0.0000001, beta1 = 0.9, beta2 = 0.999\n",
    "            *  Consider the current batch. \n",
    "            *  Feedforward: Get activation values using sigmoid function for each layer.\n",
    "            *  Back Propagation: Get error in output layer and calculate derivative of error in each hidden layers.\n",
    "                - Compute dw, db using current mini batch\n",
    "                - Vdw = Beta1*Vdw+(1-Beta1)*dw; Vdb=Beta1*Vdb+(1-Beta1)*db\n",
    "                - Sdw = Beta2*Sdw+(1-Beta2)*dw^2; Vdb=Beta1*Sdb+(1-Beta1)*db^2\n",
    "                - Compute Vdw corrected = Vdw/(1-Beta1^t); Vdb corrected = Vdb/(1-Beta1^t)\n",
    "                - Compute Sdw corrected = Sdw/(1-Beta1^t); Sdb corrected = Sdb/(1-Beta1^t)\n",
    "            * Update weights.\n",
    "                - W = W - alpha*(Vdw corrected/(sqrt(Sdw corrected)+epsilon))\n",
    "                - b = b - alpha*(Vdb corrected/(sqrt(Sdb corrected)+epsilon))\n",
    "    3. Use the updated weights and biases in feed forward to predict labels for test set. \n",
    "\n",
    "\n",
    "- Ref:https://www.youtube.com/watch?v=JXQT_vxqwIs (Andrew Ng)\n",
    "- Ref:https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam (Wiki)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait while pre processing the data...\n",
      "Selected normalisation is scale between (-1, 1)\n",
      "Please wait while model is training.... \n",
      "\n",
      "\n",
      " ************************* Classification Report on Training Data ***************************\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      5923\n",
      "           1       0.97      0.97      0.97      6742\n",
      "           2       0.94      0.94      0.94      5958\n",
      "           3       0.94      0.92      0.93      6131\n",
      "           4       0.94      0.91      0.93      5842\n",
      "           5       0.93      0.89      0.91      5421\n",
      "           6       0.97      0.95      0.96      5918\n",
      "           7       0.93      0.97      0.95      6265\n",
      "           8       0.92      0.93      0.93      5851\n",
      "           9       0.89      0.94      0.91      5949\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     60000\n",
      "   macro avg       0.94      0.94      0.94     60000\n",
      "weighted avg       0.94      0.94      0.94     60000\n",
      "\n",
      "\n",
      "\n",
      "************************** Accuracy Score - Training Data ***********************************\n",
      "\n",
      "0.9402333333333334\n",
      "Evaluating on given test data..... Please wait until next message appears.\n",
      "\n",
      "\n",
      " **************************** Classification Report on Test Data ******************************\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       980\n",
      "           1       0.97      0.97      0.97      1135\n",
      "           2       0.94      0.92      0.93      1032\n",
      "           3       0.91      0.92      0.92      1010\n",
      "           4       0.93      0.91      0.92       982\n",
      "           5       0.91      0.87      0.89       892\n",
      "           6       0.95      0.93      0.94       958\n",
      "           7       0.94      0.95      0.95      1028\n",
      "           8       0.91      0.90      0.91       974\n",
      "           9       0.88      0.93      0.91      1009\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "\n",
      "\n",
      "***************************** F1 Score - Test Data ******************************************\n",
      "\n",
      "0.9283816075850065\n",
      "\n",
      "\n",
      "***************************** Accuracy Score - Test Data ****************************************\n",
      "\n",
      "0.9295\n",
      "\n",
      "\n",
      "**************************** Confusion Matrix - Test Data **************************************\n",
      "\n",
      "[[ 962    0    4    0    1    1    4    5    3    0]\n",
      " [   0 1105    7    2    0    3    1    4   12    1]\n",
      " [  17    9  946   13    6    3    5   20   11    2]\n",
      " [   4    3   17  928    1   24    1    7   17    8]\n",
      " [   1    1    8    0  891    0    6    5    3   67]\n",
      " [  10    3    2   41    9  773   18    4   24    8]\n",
      " [  12    2   14    0    7   24  892    0    7    0]\n",
      " [   2    6    8   11    2    1    1  980    0   17]\n",
      " [   9    5    4   15   10   16    9    4  880   22]\n",
      " [   6    1    0    6   28    4    0   17    9  938]]\n"
     ]
    }
   ],
   "source": [
    "model_param = {'hidden_layer_sizes': (10, 10), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.0001,\n",
    "                               'batch_size': 'auto', 'learning_rate': 'constant', 'learning_rate_init': 0.001,\n",
    "                               'power_t': 0.5, 'max_iter': 200, 'shuffle':True, 'random_state':None, 'tol':0.0001,\n",
    "                               'verbose': False, 'warm_start': False, 'momentum': 0.9, 'nesterovs_momentum': True,\n",
    "                               'early_stopping': False, 'validation_fraction':0.1, 'beta_1': 0.9, 'beta_2': 0.999,\n",
    "                               'epsilon': 1e-08, 'n_iter_no_change': 10, 'normalization': 'min_max_norm'}\n",
    "inst = nn.NeuralNetwork(model_param)\n",
    "inst.fit(\"mnist_data/mnist_train_data.csv\", \"mnist_data/mnist_test_data.csv\")\n",
    "report, f_score, acc_score, cnf_matrix, model_coefficients = inst.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on Neural Netwrok Performance:\n",
    "\n",
    "As we see from above classification report we can see the test accuracy is satisfactory i.e. 93%. However, one need to be very carefull about neural network because it is prone to over fitting. Whether the model suffers from overfitting or under fitting can be understood by observing the training and testing accuracy. If the training accuracy is high and testing accuracy is low then model suffers from overfitting (i.e. High variance) and if the test accuracy is low and training accuracy is also low then model sufferes from underfitting (i.e high bias). Most of the time model sufferes from overfitting and undefitting is usually by the poor selection of algorithm.\n",
    "\n",
    "It is also woth noting that for multiclass classification, the precision and recall for each class is important to make sure that the selected algorithm have learned to differentiate between the classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 layer weights\n",
      "\n",
      "[[ 9.10436306e-002 -4.52721048e-002 -9.00550814e-002 ... -4.62810103e-315\n",
      "  -3.03131005e-002  5.73288198e-316]\n",
      " [ 7.66960507e-002  2.05151841e-002 -5.84689240e-003 ...  2.56302475e-315\n",
      "  -1.16465710e-001  3.18338420e-315]\n",
      " [-9.27017750e-003 -3.36514916e-002 -1.26393404e-001 ...  3.10843705e-315\n",
      "  -3.07905063e-002  4.04201262e-315]\n",
      " ...\n",
      " [ 8.31311321e-002 -9.10175459e-002  1.43404066e-002 ... -1.95139361e-315\n",
      "  -8.06858952e-002  2.49935025e-315]\n",
      " [ 1.24630773e-001 -3.65862377e-002 -4.49472191e-002 ... -3.05997698e-315\n",
      "  -4.37128754e-002  2.25840341e-315]\n",
      " [ 9.96937286e-002  2.59184042e-002 -4.55900571e-002 ... -3.62917500e-315\n",
      "  -4.70254880e-002  4.52992106e-315]]\n",
      "\n",
      "\n",
      "2 layer weights\n",
      "\n",
      "[[ 3.44639562e-001  7.63760750e-001 -6.03194135e-001  3.56635299e-001\n",
      "  -7.64796469e-002  8.54429571e-001  2.08796527e-315  1.15930056e+000\n",
      "  -6.59576644e-001  1.00313449e+000]\n",
      " [ 5.78109778e-001 -9.41501435e-001  1.14915969e-001  2.20278239e-002\n",
      "  -5.38298357e-001 -1.47743976e-001  4.44495002e-317  2.35436775e-001\n",
      "   5.83051702e-001  2.99276484e-001]\n",
      " [ 5.07548881e-001 -7.11275379e-002  8.83442128e-001  1.05892282e+000\n",
      "  -2.90417238e-003  2.56664419e-001  4.26743266e-315  6.38566014e-001\n",
      "  -1.25736371e-001  3.44543223e-001]\n",
      " [-6.19203229e-001  2.80382659e-001  6.95189348e-002 -3.91504466e-002\n",
      "   4.06743102e-001  8.02217054e-001 -1.47580637e-315 -7.51818302e-002\n",
      "   5.58588733e-001  7.10031367e-001]\n",
      " [-5.47773582e-001 -3.22883994e-001 -1.09344859e-001  8.03571472e-001\n",
      "  -1.77785243e-001 -2.52428410e-001  1.18982361e-315  2.28381472e-002\n",
      "   1.78710550e-001 -4.30917527e-001]\n",
      " [ 4.58922796e-001  4.92339935e-002  3.86058968e-001  1.92069844e-001\n",
      "  -3.70544723e-001  5.02223681e-001 -1.41797862e-315 -3.63123116e-001\n",
      "  -1.12206936e-001 -4.68970272e-002]\n",
      " [ 1.09151838e-316  1.86489265e-315  3.64758309e-315  3.34910950e-316\n",
      "   3.76024633e-316 -2.20689052e-315  2.54416778e-315 -1.04379608e-315\n",
      "  -4.98189019e-316 -4.96293250e-315]\n",
      " [-1.45385725e-315  4.53630849e-316 -5.15499987e-316 -4.57934383e-316\n",
      "   1.05315001e-315  4.32553697e-316  1.35550505e-315 -5.77823276e-316\n",
      "   3.87289225e-315  2.75446410e-316]\n",
      " [-3.17837924e-002  4.00242302e-001  3.56459903e-001 -2.81045309e-001\n",
      "   1.07113766e-001  6.57971668e-001  1.66143177e-315  7.11027472e-001\n",
      "   7.37984552e-001 -2.86826022e-001]\n",
      " [ 4.80916612e-316  1.92609886e-316  2.44941551e-315  3.38986504e-315\n",
      "   4.65748539e-315 -4.19560489e-315 -4.51966657e-315  3.16588694e-316\n",
      "  -7.50780313e-316  4.14385673e-316]]\n",
      "\n",
      "\n",
      "3 layer weights\n",
      "\n",
      "[[-8.08218170e-003 -3.60455440e-001  5.42921431e-001 -7.47027621e-002\n",
      "   4.27944020e-001  1.30710931e-002  8.63784314e-001 -8.84727255e-002\n",
      "  -7.57845310e-002 -6.12099377e-001]\n",
      " [-1.97638835e-001  1.00974337e+000  8.05058166e-001  1.29771820e-001\n",
      "  -2.48568360e-002  8.88575050e-002 -1.51822636e-001  7.92707500e-001\n",
      "  -2.42759948e-001  8.70076756e-001]\n",
      " [ 1.51986382e-001 -1.18000871e-002 -5.67365627e-001  4.03167077e-002\n",
      "  -4.18726616e-001  4.81925243e-001 -3.74594501e-001 -1.38176579e+000\n",
      "  -2.99113524e-003  2.80282908e-001]\n",
      " [-9.85544824e-001  3.89153351e-001 -4.47288517e-002  2.88967881e-001\n",
      "   4.83421128e-001 -5.13826261e-001 -1.10514270e+000  3.79697864e-001\n",
      "   1.24337546e-001  4.26095785e-001]\n",
      " [-8.32617348e-001  5.70015926e-001 -8.48558495e-001  3.07193729e-001\n",
      "  -3.99176573e+000  4.48411751e-001 -6.18447158e-001 -5.25682307e-001\n",
      "  -9.19557496e-001  3.93485266e-002]\n",
      " [-1.66986867e-001  4.10164029e-001  9.55806477e-002 -2.75337885e-002\n",
      "  -8.79041303e-001 -1.39027926e-002  6.05130397e-001 -4.23934155e-001\n",
      "   4.34418296e-001 -7.07216462e-001]\n",
      " [-2.32217754e-315  3.05949834e-315 -3.38473772e-315 -2.44203590e-315\n",
      "  -2.73503828e-316 -1.47256557e-316  8.64239203e-316 -3.53936255e-315\n",
      "   6.81862355e-316 -4.43497587e-316]\n",
      " [ 5.84617339e-003  6.23963497e-001  2.71923667e-001  4.88111102e-001\n",
      "  -1.15935223e+000  8.20485429e-001  2.03311751e-002  4.09155403e-001\n",
      "  -7.50198448e-001 -5.95133546e-001]\n",
      " [ 7.39896791e-001 -1.00822037e+000  1.29737430e-001 -1.39193292e-001\n",
      "   8.80851888e-002  1.57900218e-001  3.05900771e-001  4.16988583e-001\n",
      "  -9.92297227e-002  3.37297035e-001]\n",
      " [ 1.66870961e-001 -1.22992220e+000  3.25373875e-001  1.87274937e-001\n",
      "   7.60795439e-001 -6.45031935e-001 -9.72160618e-001  1.92313995e-001\n",
      "  -5.18065314e-001  8.66806926e-002]]\n"
     ]
    }
   ],
   "source": [
    "for index, coef in enumerate(model_coefficients):\n",
    "    print('\\n\\n{} layer weights\\n'.format(index+1))\n",
    "    print(coef.shape)\n",
    "    print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
